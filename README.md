# ğŸ“š Agentic RAG Chatbot using MCP (Ollama Edition)

This project is a **local, private, document-based chatbot** built using the **Model Context Protocol (MCP)** with **agentic architecture**. It uses `Ollama` for running local LLMs like `llama3` and lets users upload PDF, DOCX, CSV, TXT, and PPTX files to query them in natural language.

## ğŸ§  Project Features

- ğŸ” Retrieval-Augmented Generation (RAG) with FAISS and Ollama
- ğŸ¤– Agent-based flow: Ingestion, Retrieval, and LLM Response Agents
- ğŸ“‚ Supports multi-format file uploads (.pdf, .docx, .txt, .csv, .pptx)
- ğŸ§  Embedding via MiniLM transformer
- âš™ï¸ Local LLM inference using Ollama
- ğŸ–¥ï¸ User-friendly Streamlit interface

## ğŸ¥ Video Demo

ğŸ“º https://www.loom.com/share/0c4146e2f75c4d22b752408b3c63e409

## ğŸš€ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/your-username/agentic-rag-ollama
cd agentic-rag-ollama
```

### 2. Create Environment & Install Dependencies
```bash
python -m venv venv
venv\Scripts\activate   # Use 'source venv/bin/activate' for Linux/macOS
pip install -r requirements.txt
```

### 3. Start Ollama and Pull Model
```bash
ollama pull llama3
ollama run llama3
```

### 4. Launch the App
```bash
streamlit run app.py
```

## ğŸ§© Architecture

```
User â†” Streamlit UI â†” MCP Bus
      â”œâ”€â”€ IngestionAgent â†’ Parse docs + Embed chunks â†’ Store in FAISS
      â”œâ”€â”€ RetrievalAgent â†’ Embed query â†’ Search FAISS â†’ Top Chunks
      â””â”€â”€ LLMResponseAgent â†’ Use Ollama to answer with context
```

## ğŸ“‚ Project Structure

```
ğŸ“ agentic-rag-ollama
â”œâ”€â”€ app.py               # Main Streamlit UI
â”œâ”€â”€ mcp.py               # Message passing protocol
â”œâ”€â”€ agents_and_utils.py  # All agent classes + FAISS logic
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # This file
```

## âœ… Dependencies

- streamlit  
- faiss-cpu  
- sentence-transformers  
- PyMuPDF (fitz)  
- python-docx  
- python-pptx  
- ollama  

Install them using:
```bash
pip install -r requirements.txt
```

## ğŸ‘¤ Author

**Vishnu**  
Agentic RAG + Ollama + Streamlit Project powered by LLMs ğŸ”ğŸ¤–ğŸ“„
